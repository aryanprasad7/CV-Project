{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFO7DMo0bNhm"
   },
   "source": [
    "# **Image Super-Resolution**\n",
    "**64x64 -> 512x512**\n",
    "\n",
    "A colab notebook for upscaling 64x64 images to 512x512, using [this](https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YpW_YQQaa8U"
   },
   "source": [
    "## Setup\n",
    "---\n",
    "Instructions:\n",
    "\n",
    "*   Turn on hardware acceleration under `Runtime -> Change Runtime Type -> Hardware accelerator -> GPU`\n",
    "*   Use this command to ensure that the connected machine has a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWHYjb8WanA3",
    "outputId": "d697ecdb-b65c-4ace-cbad-623b6a836755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, driver_version, memory.total [MiB]\n",
      "Tesla V100-PCIE-32GB, 535.154.05, 32768 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcKEMsB4b3IB"
   },
   "source": [
    "*    Now, execute each cell sequentially, waiting until each one is done before running the next cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxwQpOG8cXHx"
   },
   "source": [
    "### Clone repo, download a pre-trained model, install dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wZutZK1hPJp",
    "outputId": "db851604-2fe7-400a-822e-b5e0320ddd8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/'\n",
      "/scratch/rv1057\n",
      "Cloning into 'Image-Super-Resolution-via-Iterative-Refinement'...\n",
      "remote: Enumerating objects: 569, done.\u001b[K\n",
      "remote: Counting objects: 100% (568/568), done.\u001b[K\n",
      "remote: Compressing objects: 100% (286/286), done.\u001b[K\n",
      "remote: Total 569 (delta 298), reused 472 (delta 267), pack-reused 1 (from 1)\u001b[K\n",
      "Receiving objects: 100% (569/569), 10.01 MiB | 56.60 MiB/s, done.\n",
      "Resolving deltas: 100% (298/298), done.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorboardx\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from tensorboardx) (1.26.4)\n",
      "Requirement already satisfied: packaging in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from tensorboardx) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from tensorboardx) (3.20.3)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboardx\n",
      "Successfully installed tensorboardx-2.6.2.2\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "!git clone https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboardx in /home/rv1057/.local/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from tensorboardx) (1.26.4)\n",
      "Requirement already satisfied: packaging in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from tensorboardx) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from tensorboardx) (3.20.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.5.1 (from torchvision)\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: networkx in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.1->torchvision)\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1->torchvision)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardx\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPmBAIBGBtsM",
    "outputId": "c7dec506-d8c1-42a3-df42-6d65d2f1e68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lmdb in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (1.4.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from requests[socks]->gdown) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHqLHR4gw_tU"
   },
   "source": [
    "**NOTE: The `gdown` command does not always work.** If it gives you an error, as a temporary workaround, you must manually upload files for the pre-trained model. Download the files [here](https://drive.google.com/drive/folders/1mCiWhFqHyjt5zE4IdA41fjFwCYdqDzSF) (you may have to log into your google account to be able to do so). Then, click the `files` button on the left hand side of the screen, and find the folder labled `Image-Super-Resolution-via-Iterative-Refinement`. Click the three dots on the right of the folder, and click `upload`. Now, select the model files that you downloaded.\n",
    "\n",
    "**ALTERNATIVELY: if you plan to use this script frequently, you can make a copy of the model files in your own google drive.** Go [here](https://drive.google.com/drive/folders/1mCiWhFqHyjt5zE4IdA41fjFwCYdqDzSF), right click on each file, and hit `Make a copy`. Next, locate the files in your own google drive, and rename them from `Copy of I830000_E32_opt.pth` and `Copy of I830000_E32_gen.pth` to `I830000_E32_opt.pth` and `I830000_E32_gen.pth`. Next, right click on each file, and hit `Get link`. Click on `Restricted`, and change it to `Anyone with the link...`, as `Viewer`. Now, copy the links. They should look something like this: `https://drive.google.com/file/d/<file id>/view?usp=sharing` - copy the ids, and paste them into the `gdown` commands below.  \n",
    "\n",
    "For some reason, the model files are getting rate limited at times. This will hopefully be fixed in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SproHDsaMRyf",
    "outputId": "73476088-4ae0-4dbf-985f-653fc89d197c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/Image-Super-Resolution-via-Iterative-Refinement/'\n",
      "/scratch/rv1057\n",
      "/home/rv1057/.local/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1M015uQG8cq0mqwhEfc7klFJwDr2jsYSr\n",
      "From (redirected): https://drive.google.com/uc?id=1M015uQG8cq0mqwhEfc7klFJwDr2jsYSr&confirm=t&uuid=a398f2e5-ff55-4930-b0f9-86acf891e6a3\n",
      "To: /scratch/rv1057/I830000_E32_opt.pth\n",
      "100%|██████████████████████████████████████| 1.24G/1.24G [00:25<00:00, 48.0MB/s]\n",
      "/home/rv1057/.local/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Vwe1Raa-Dpop75o5v7O5qvGoOdFDlyc-\n",
      "From (redirected): https://drive.google.com/uc?id=1Vwe1Raa-Dpop75o5v7O5qvGoOdFDlyc-&confirm=t&uuid=f6004b72-2839-4f81-9fca-4e5341415acb\n",
      "To: /scratch/rv1057/I830000_E32_gen.pth\n",
      "100%|████████████████████████████████████████| 622M/622M [00:15<00:00, 39.1MB/s]\n",
      "[Errno 2] No such file or directory: '/content/Image-Super-Resolution-via-Iterative-Refinement/config/'\n",
      "/scratch/rv1057\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Image-Super-Resolution-via-Iterative-Refinement/\n",
    "!gdown --id 1M015uQG8cq0mqwhEfc7klFJwDr2jsYSr\n",
    "!gdown --id 1Vwe1Raa-Dpop75o5v7O5qvGoOdFDlyc-\n",
    "%cd /content/Image-Super-Resolution-via-Iterative-Refinement/config/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpQUl1Ce9ycZ"
   },
   "source": [
    "Once you have done training at least once and saved it somewhere (preferably on Google Drive), you can use your trained checkpoint instead of the original model. Like for checkpoints saved in https://drive.google.com/drive/u/0/folders/1YPr5TWcHiDhifOSqS_ZaD36Zm7WDZdGR, you can just get them using the procedure from above: **Alternatively**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2x7hIo08-O14",
    "outputId": "20e94b7b-fe79-4d84-f083-bd3693975c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Image-Super-Resolution-via-Iterative-Refinement/'\n",
      "/scratch/rv1057\n",
      "/home/rv1057/.local/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-HpBSYQs_QrUDrdIXo1jEQ8JZf17pO8z\n",
      "From (redirected): https://drive.google.com/uc?id=1-HpBSYQs_QrUDrdIXo1jEQ8JZf17pO8z&confirm=t&uuid=0cca3b1a-9bce-4b9b-884f-36798bc798ff\n",
      "To: /scratch/rv1057/I831000_E532_opt.pth\n",
      "100%|██████████████████████████████████████| 1.24G/1.24G [00:26<00:00, 47.3MB/s]\n",
      "/home/rv1057/.local/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-ADxQK2BKiUtjocpWAoqzIDpTYW9Qwxi\n",
      "From (redirected): https://drive.google.com/uc?id=1-ADxQK2BKiUtjocpWAoqzIDpTYW9Qwxi&confirm=t&uuid=46c9af01-4cfc-4d5a-9421-5dac382186ba\n",
      "To: /scratch/rv1057/I831000_E532_gen.pth\n",
      "100%|████████████████████████████████████████| 622M/622M [00:10<00:00, 60.2MB/s]\n",
      "[Errno 2] No such file or directory: '/Image-Super-Resolution-via-Iterative-Refinement/config/'\n",
      "/scratch/rv1057\n"
     ]
    }
   ],
   "source": [
    "%cd /Image-Super-Resolution-via-Iterative-Refinement/\n",
    "!gdown --id 1-HpBSYQs_QrUDrdIXo1jEQ8JZf17pO8z\n",
    "!gdown --id 1-ADxQK2BKiUtjocpWAoqzIDpTYW9Qwxi\n",
    "%cd /Image-Super-Resolution-via-Iterative-Refinement/config/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx9_SzGrcvqt"
   },
   "source": [
    "### Patch config files\n",
    "\n",
    "Create patchfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_Sv8UJu0d5i",
    "outputId": "9e73a157-3f7b-4360-8084-95eee58dba7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 64_512.patch\n"
     ]
    }
   ],
   "source": [
    "%%writefile 64_512.patch\n",
    "--- sr_sr3_64_512_new.json\t2021-10-22 16:20:20.901133618 +0000\n",
    "+++ sr_sr3_64_512.json\t2021-10-22 16:20:52.036081672 +0000\n",
    "@@ -9,8 +9,8 @@\n",
    "         \"tb_logger\": \"tb_logger\",\n",
    "         \"results\": \"results\",\n",
    "         \"checkpoint\": \"checkpoint\",\n",
    "-        \"resume_state\": null\n",
    "-        // \"resume_state\": \"experiments/distributed_high_sr_ffhq_210901_121212/checkpoint/I830000_E32\" //pretrain model or training state\n",
    "+        // \"resume_state\": null\n",
    "+        \"resume_state\": \"I830000_E32\" //pretrain model or training state\n",
    "     },\n",
    "     \"datasets\": {\n",
    "         \"train\": {\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ix9vWlDmc8zu"
   },
   "source": [
    "Apply patchfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvA6tCTk5N8d",
    "outputId": "37506088-3e93-4c70-8ca0-bc82c9792408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos2unix: converting file Image-Super-Resolution-via-Iterative-Refinement/config/sr_sr3_64_512.json to Unix format...\n",
      "can't find file to patch at input line 3\n",
      "Perhaps you should have used the -p or --strip option?\n",
      "The text leading up to this was:\n",
      "--------------------------\n",
      "|--- sr_sr3_64_512_new.json\t2021-10-22 16:20:20.901133618 +0000\n",
      "|+++ sr_sr3_64_512.json\t2021-10-22 16:20:52.036081672 +0000\n",
      "--------------------------\n",
      "File to patch: ^C\n"
     ]
    }
   ],
   "source": [
    "#!apt-get install dos2unix\n",
    "!dos2unix Image-Super-Resolution-via-Iterative-Refinement/config/sr_sr3_64_512.json\n",
    "!patch < 64_512.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYpuGLzAdSi6"
   },
   "source": [
    "### Prepair Data\n",
    "Upload 64x64 pixel image(s) to be upscaled\n",
    "\n",
    "*Click the **browse** button and select the images you would like to upscale.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsqL17JOFd6N"
   },
   "source": [
    "Create a folder for a dataset. Folder structure:\n",
    "\n",
    "*   lr_64 (64 by 64) low-res images\n",
    "*   hr_512 (512 by 512) high-res images, ground-truth. If you do not have it, the system will put a copy of sr_64_512 with name hr_512 when you call prepare_data.py\n",
    "*   sr_64_512 (512 by 512) basic upscaled (bicubic or something) versions of low-res images from lr_64. This will be used as a starting image for inference/training. You DO NOT need to create it, call prepare_data.py to generate it from lr_64.\n",
    "\n",
    "Corresponding images in all 3 datasets should have the same names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MUL8gPkHIRD"
   },
   "source": [
    "Move your dataset to dataset folder, make sure it follows the instructions from above. Update the sr_sr3_64_512.json with your datafile. Alternatively, just replace appropriate folders in celebahq_64_512 and ffhq_64_512 with yours, delete sr_64_512."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEOiBK5ldm1M"
   },
   "source": [
    "Generate neccesary files and directory structure to begin upscaling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64_512.patch          \u001b[0m\u001b[01;34mImage-Super-Resolution-via-Iterative-Refinement\u001b[0m/\n",
      "I830000_E32_gen.pth   Running_and_Training_SR3_HPC.ipynb\n",
      "I830000_E32_opt.pth   \u001b[01;34mbig_data\u001b[0m/\n",
      "I831000_E532_gen.pth  \u001b[01;34mcontent\u001b[0m/\n",
      "I831000_E532_opt.pth\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2NnTm92jOUyK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Image-Super-Resolution-via-Iterative-Refinement/dataset'\n",
      "/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset\n",
      "/home/rv1057/.local/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Retrieving folder contents\n",
      "Retrieving folder 1h3qDSB_4Sdxk-JXZ9BGiA2XksVwIqFkQ hr_512\n",
      "Processing file 1lDyOBf5PB-Q3kYIprwpUz_Z23EZ1aj7z ER.png\n",
      "Processing file 1K2Mzp8rIBEZTvy_3bLx8s6sXxVS5tGUa f_non.png\n",
      "Processing file 1Rj-EHbrlL_MvbUiYqj2aSAw6Qf3ifw8_ micro.png\n",
      "Retrieving folder 1a2DMHmRJNAv_2CgOnxOhbftrD-AdOJc2 lr_64\n",
      "Processing file 1zQvRz9p-OXA3CbXg5mgnHbFj9M7g3luJ ER.png\n",
      "Processing file 11zMwCj7dwAaTlQANIAo_vFrafHpElcVr f_non.png\n",
      "Processing file 1yb2tvoNaYTJK4HIAm628QgEmnjj1fHA3 micro.png\n",
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lDyOBf5PB-Q3kYIprwpUz_Z23EZ1aj7z\n",
      "To: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/MIX/hr_512/ER.png\n",
      "100%|████████████████████████████████████████| 112k/112k [00:00<00:00, 5.70MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1K2Mzp8rIBEZTvy_3bLx8s6sXxVS5tGUa\n",
      "To: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/MIX/hr_512/f_non.png\n",
      "100%|████████████████████████████████████████| 184k/184k [00:00<00:00, 4.54MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Rj-EHbrlL_MvbUiYqj2aSAw6Qf3ifw8_\n",
      "To: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/MIX/hr_512/micro.png\n",
      "100%|████████████████████████████████████████| 142k/142k [00:00<00:00, 3.61MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zQvRz9p-OXA3CbXg5mgnHbFj9M7g3luJ\n",
      "To: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/MIX/lr_64/ER.png\n",
      "100%|██████████████████████████████████████| 2.26k/2.26k [00:00<00:00, 13.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11zMwCj7dwAaTlQANIAo_vFrafHpElcVr\n",
      "To: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/MIX/lr_64/f_non.png\n",
      "100%|██████████████████████████████████████| 2.94k/2.94k [00:00<00:00, 22.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yb2tvoNaYTJK4HIAm628QgEmnjj1fHA3\n",
      "To: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/MIX/lr_64/micro.png\n",
      "100%|██████████████████████████████████████| 2.76k/2.76k [00:00<00:00, 20.5MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "%cd Image-Super-Resolution-via-Iterative-Refinement/dataset\n",
    "!gdown --id --folder 1CzPGcF4azeZ1GsUpIZasXIA6Exh_4gyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yzjp75wSL4WU"
   },
   "source": [
    "Call prepare_data.py on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64_512.patch          \u001b[0m\u001b[01;34mImage-Super-Resolution-via-Iterative-Refinement\u001b[0m/\n",
      "I830000_E32_gen.pth   Running_and_Training_SR3_HPC.ipynb\n",
      "I830000_E32_opt.pth   \u001b[01;34mbig_data\u001b[0m/\n",
      "I831000_E532_gen.pth  \u001b[01;34mcontent\u001b[0m/\n",
      "I831000_E532_opt.pth\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/Microtubules/high_res/Cell_001_RawSIMData_gt.png /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/Microtubules_val/high_res/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GNfEu9gsseU",
    "outputId": "c801de41-542e-489f-c164-5eaa3a751d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/500 images processed                                                                                                                                                                                                                                                                                                                                                                           "
     ]
    }
   ],
   "source": [
    "!python /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/data/prepare_data.py --path /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/F-actin_Nonlinear/a/low_res --size 64,512 --out /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/train_FNa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qIaqgChM-je",
    "outputId": "7c6a56c4-0e09-4529-9940-5abc57decc8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2 images processed  "
     ]
    }
   ],
   "source": [
    "!python /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/data/prepare_data.py --path /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/F-actin_Nonlinear_val/a/low_res --size 64,512 --out /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/val_FNa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vACVBR7PNU-F"
   },
   "outputs": [],
   "source": [
    "%rm -r /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/train_FNa_64_512/hr_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hrQBNJWuNdgi"
   },
   "outputs": [],
   "source": [
    "%rm -r /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/val_FNa_64_512/hr_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0dgn9ElQM3Xm"
   },
   "outputs": [],
   "source": [
    "%cp -r /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/F-actin_Nonlinear/a/high_res /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/train_FNa_64_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "VfEFVLs5M8iu"
   },
   "outputs": [],
   "source": [
    "%cp -r /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/F-actin_Nonlinear/a/high_res /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/val_FNa_64_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cE6wku6Iksvs",
    "outputId": "6ec4a36d-956c-472c-c6fd-1556e323efd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121\n"
     ]
    }
   ],
   "source": [
    "%ls /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/dataset/train_64_512/sr_64_512 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsF6C2sgeuyq"
   },
   "source": [
    "## Upscaling\n",
    "---\n",
    "For inference run this code, it takes ~10 minutes on T4. This will generate a folder on experiments (every job gets a new folder). In the folder, results contains your resulting iamges. The codes are the same as for datasets: inf means upscaled low-res image, hr means ground-truth, sr means the output of diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /share/apps/anaconda3/2024.02/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement\n"
     ]
    }
   ],
   "source": [
    "%cd Image-Super-Resolution-via-Iterative-Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUS4C0ZYc578",
    "outputId": "59865e57-940d-49ab-a4e2-56b5de29b1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=0,1,2\n",
      "24-12-20 20:56:15.306 - INFO:   name: distributed_high_sr_ffhq\n",
      "  phase: val\n",
      "  gpu_ids: [0, 1, 2]\n",
      "  path:[\n",
      "    log: experiments/distributed_high_sr_ffhq_241220_205615/logs\n",
      "    tb_logger: experiments/distributed_high_sr_ffhq_241220_205615/tb_logger\n",
      "    results: experiments/distributed_high_sr_ffhq_241220_205615/results\n",
      "    checkpoint: experiments/distributed_high_sr_ffhq_241220_205615/checkpoint\n",
      "    resume_state: /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/experiments/distributed_high_sr_ffhq_241219_102240/checkpoint/I890000_E251\n",
      "    experiments_root: experiments/distributed_high_sr_ffhq_241220_205615\n",
      "  ]\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: Train\n",
      "      mode: HR\n",
      "      dataroot: dataset/train_micro_64_512\n",
      "      datatype: img\n",
      "      l_resolution: 64\n",
      "      r_resolution: 512\n",
      "      batch_size: 2\n",
      "      num_workers: 1\n",
      "      use_shuffle: True\n",
      "      data_len: -1\n",
      "    ]\n",
      "    val:[\n",
      "      name: Validation\n",
      "      mode: LRHR\n",
      "      dataroot: dataset/val_micro_64_512\n",
      "      datatype: img\n",
      "      l_resolution: 64\n",
      "      r_resolution: 512\n",
      "      data_len: 50\n",
      "    ]\n",
      "  ]\n",
      "  model:[\n",
      "    which_model_G: sr3\n",
      "    finetune_norm: False\n",
      "    unet:[\n",
      "      in_channel: 6\n",
      "      out_channel: 3\n",
      "      inner_channel: 64\n",
      "      norm_groups: 16\n",
      "      channel_multiplier: [1, 2, 4, 8, 16]\n",
      "      attn_res: []\n",
      "      res_blocks: 1\n",
      "      dropout: 0\n",
      "    ]\n",
      "    beta_schedule:[\n",
      "      train:[\n",
      "        schedule: linear\n",
      "        n_timestep: 2000\n",
      "        linear_start: 1e-06\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "      val:[\n",
      "        schedule: linear\n",
      "        n_timestep: 2000\n",
      "        linear_start: 1e-06\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "    ]\n",
      "    diffusion:[\n",
      "      image_size: 512\n",
      "      channels: 3\n",
      "      conditional: True\n",
      "    ]\n",
      "  ]\n",
      "  train:[\n",
      "    n_iter: 840000\n",
      "    val_freq: 840000\n",
      "    save_checkpoint_freq: 5000\n",
      "    print_freq: 50\n",
      "    optimizer:[\n",
      "      type: adam\n",
      "      lr: 3e-06\n",
      "    ]\n",
      "    ema_scheduler:[\n",
      "      step_start_ema: 5000\n",
      "      update_ema_every: 1\n",
      "      ema_decay: 0.9999\n",
      "    ]\n",
      "  ]\n",
      "  wandb:[\n",
      "    project: distributed_high_sr_ffhq\n",
      "  ]\n",
      "  distributed: True\n",
      "  log_infer: False\n",
      "  enable_wandb: False\n",
      "\n",
      "24-12-20 20:56:15.310 - INFO: Dataset [LRHRDataset - Validation] is created.\n",
      "24-12-20 20:56:15.310 - INFO: Initial Dataset Finished\n",
      "24-12-20 20:56:16.753 - INFO: Loading pretrained model for G [/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/experiments/distributed_high_sr_ffhq_241219_102240/checkpoint/I890000_E251] ...\n",
      "/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/model/model.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network.load_state_dict(torch.load(\n",
      "24-12-20 20:56:18.784 - INFO: Network G structure: DataParallel - GaussianDiffusion, with parameters: 155,334,339\n",
      "24-12-20 20:56:18.785 - INFO: GaussianDiffusion(\n",
      "  (denoise_fn): UNet(\n",
      "    (noise_level_mlp): Sequential(\n",
      "      (0): PositionalEncoding()\n",
      "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (2): Swish()\n",
      "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "    (downs): ModuleList(\n",
      "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Downsample(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Downsample(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ups): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (6): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (10): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (11): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (12): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Block(\n",
      "      (block): Sequential(\n",
      "        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "        (1): Swish()\n",
      "        (2): Identity()\n",
      "        (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): L1Loss()\n",
      ")\n",
      "24-12-20 20:56:18.790 - INFO: Model [DDPM] is created.\n",
      "24-12-20 20:56:18.790 - INFO: Initial Model Finished\n",
      "24-12-20 20:56:18.791 - INFO: Begin Model Inference.\n",
      "sampling loop time step: 100%|██████████████| 2000/2000 [03:10<00:00, 10.48it/s]\n"
     ]
    }
   ],
   "source": [
    "!python /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/infer.py -c /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/config/sr_sr3_64_512.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktRjpBpYsV2y"
   },
   "source": [
    "##Training\n",
    "\n",
    "Before training open sr_sr3_64_512.json file from config. Find the place that starts as:\n",
    "\n",
    "\"\n",
    "train\": {\n",
    "        \"n_iter\":\n",
    "\"\n",
    "\n",
    "Modify the following parameters.\n",
    "* n_iter. Preloaded checkpoint has 830,000 iterations, so if, for example, you want to do 1,000 iterations, you should set it to 831,000.\n",
    "* Set val_freq to how often you want to validate on validation dataset (i.e. 100 means every 100 iterations), if you don't want to validate, set it to >number of iterations.\n",
    "* Same for save_checkpoint_freq, but make sure you save at least one checkpoint. So, set it to 1000 if you are doign 1000 iterations\n",
    "* print_freq same, how often you want loss and updates to be printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktRjpBpYsV2y"
   },
   "source": [
    "##Training\n",
    "\n",
    "Before training open sr_sr3_64_512.json file from config. Find the place that starts as:\n",
    "\n",
    "\"\n",
    "train\": {\n",
    "        \"n_iter\":\n",
    "\"\n",
    "\n",
    "Modify the following parameters.\n",
    "* n_iter. Preloaded checkpoint has 830,000 iterations, so if, for example, you want to do 1,000 iterations, you should set it to 831,000.\n",
    "* Set val_freq to how often you want to validate on validation dataset (i.e. 100 means every 100 iterations), if you don't want to validate, set it to >number of iterations.\n",
    "* Same for save_checkpoint_freq, but make sure you save at least one checkpoint. So, set it to 1000 if you are doign 1000 iterations\n",
    "* print_freq same, how often you want loss and updates to be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2w2AmiXfSGLI",
    "outputId": "28a940da-4529-48df-80d0-586d503aea8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=0,1,2\n",
      "24-12-20 17:11:59.846 - INFO:   name: distributed_high_sr_ffhq\n",
      "  phase: train\n",
      "  gpu_ids: [0, 1, 2]\n",
      "  path:[\n",
      "    log: experiments/distributed_high_sr_ffhq_241220_171159/logs\n",
      "    tb_logger: experiments/distributed_high_sr_ffhq_241220_171159/tb_logger\n",
      "    results: experiments/distributed_high_sr_ffhq_241220_171159/results\n",
      "    checkpoint: experiments/distributed_high_sr_ffhq_241220_171159/checkpoint\n",
      "    resume_state: I830000_E32\n",
      "    experiments_root: experiments/distributed_high_sr_ffhq_241220_171159\n",
      "  ]\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: Train\n",
      "      mode: HR\n",
      "      dataroot: dataset/train_FNa_64_512\n",
      "      datatype: img\n",
      "      l_resolution: 64\n",
      "      r_resolution: 512\n",
      "      batch_size: 2\n",
      "      num_workers: 1\n",
      "      use_shuffle: True\n",
      "      data_len: -1\n",
      "    ]\n",
      "    val:[\n",
      "      name: Validation\n",
      "      mode: LRHR\n",
      "      dataroot: dataset/val_FNa_64_512\n",
      "      datatype: img\n",
      "      l_resolution: 64\n",
      "      r_resolution: 512\n",
      "      data_len: 3\n",
      "    ]\n",
      "  ]\n",
      "  model:[\n",
      "    which_model_G: sr3\n",
      "    finetune_norm: False\n",
      "    unet:[\n",
      "      in_channel: 6\n",
      "      out_channel: 3\n",
      "      inner_channel: 64\n",
      "      norm_groups: 16\n",
      "      channel_multiplier: [1, 2, 4, 8, 16]\n",
      "      attn_res: []\n",
      "      res_blocks: 1\n",
      "      dropout: 0\n",
      "    ]\n",
      "    beta_schedule:[\n",
      "      train:[\n",
      "        schedule: linear\n",
      "        n_timestep: 2000\n",
      "        linear_start: 1e-06\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "      val:[\n",
      "        schedule: linear\n",
      "        n_timestep: 2000\n",
      "        linear_start: 1e-06\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "    ]\n",
      "    diffusion:[\n",
      "      image_size: 512\n",
      "      channels: 3\n",
      "      conditional: True\n",
      "    ]\n",
      "  ]\n",
      "  train:[\n",
      "    n_iter: 840000\n",
      "    val_freq: 840000\n",
      "    save_checkpoint_freq: 5000\n",
      "    print_freq: 50\n",
      "    optimizer:[\n",
      "      type: adam\n",
      "      lr: 3e-06\n",
      "    ]\n",
      "    ema_scheduler:[\n",
      "      step_start_ema: 5000\n",
      "      update_ema_every: 1\n",
      "      ema_decay: 0.9999\n",
      "    ]\n",
      "  ]\n",
      "  wandb:[\n",
      "    project: distributed_high_sr_ffhq\n",
      "  ]\n",
      "  distributed: True\n",
      "  log_wandb_ckpt: False\n",
      "  log_eval: False\n",
      "  enable_wandb: False\n",
      "\n",
      "24-12-20 17:11:59.853 - INFO: Dataset [LRHRDataset - Train] is created.\n",
      "24-12-20 17:11:59.854 - INFO: Dataset [LRHRDataset - Validation] is created.\n",
      "24-12-20 17:11:59.855 - INFO: Initial Dataset Finished\n",
      "24-12-20 17:12:00.976 - INFO: Initialization method [orthogonal]\n",
      "24-12-20 17:12:13.896 - INFO: Loading pretrained model for G [I830000_E32] ...\n",
      "/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/model/model.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network.load_state_dict(torch.load(\n",
      "/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/model/model.py:163: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  opt = torch.load(opt_path)\n",
      "24-12-20 17:12:17.659 - INFO: Network G structure: DataParallel - GaussianDiffusion, with parameters: 155,334,339\n",
      "24-12-20 17:12:17.659 - INFO: GaussianDiffusion(\n",
      "  (denoise_fn): UNet(\n",
      "    (noise_level_mlp): Sequential(\n",
      "      (0): PositionalEncoding()\n",
      "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (2): Swish()\n",
      "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "    (downs): ModuleList(\n",
      "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Downsample(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Downsample(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ups): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (6): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (10): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (11): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (12): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Block(\n",
      "      (block): Sequential(\n",
      "        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "        (1): Swish()\n",
      "        (2): Identity()\n",
      "        (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): L1Loss()\n",
      ")\n",
      "24-12-20 17:12:17.662 - INFO: Model [DDPM] is created.\n",
      "24-12-20 17:12:17.662 - INFO: Initial Model Finished\n",
      "24-12-20 17:12:17.662 - INFO: Resuming training from epoch: 32, iter: 830000.\n",
      "24-12-20 17:13:13.559 - INFO: <epoch: 33, iter: 830,050> l_pix: 8.8292e-02 \n",
      "24-12-20 17:13:38.421 - INFO: <epoch: 33, iter: 830,100> l_pix: 4.1754e-01 \n",
      "24-12-20 17:14:03.304 - INFO: <epoch: 33, iter: 830,150> l_pix: 3.4642e-02 \n",
      "24-12-20 17:14:28.287 - INFO: <epoch: 33, iter: 830,200> l_pix: 2.2417e-02 \n",
      "24-12-20 17:14:53.185 - INFO: <epoch: 33, iter: 830,250> l_pix: 5.8201e-02 \n",
      "24-12-20 17:15:18.276 - INFO: <epoch: 34, iter: 830,300> l_pix: 5.6540e-02 \n",
      "24-12-20 17:15:43.225 - INFO: <epoch: 34, iter: 830,350> l_pix: 1.1008e-02 \n",
      "24-12-20 17:16:08.211 - INFO: <epoch: 34, iter: 830,400> l_pix: 2.2411e-01 \n",
      "24-12-20 17:16:33.249 - INFO: <epoch: 34, iter: 830,450> l_pix: 6.4725e-03 \n",
      "24-12-20 17:16:58.205 - INFO: <epoch: 34, iter: 830,500> l_pix: 4.3971e-03 \n",
      "24-12-20 17:17:23.307 - INFO: <epoch: 35, iter: 830,550> l_pix: 8.5843e-03 \n",
      "24-12-20 17:17:48.349 - INFO: <epoch: 35, iter: 830,600> l_pix: 7.9542e-03 \n",
      "24-12-20 17:18:13.393 - INFO: <epoch: 35, iter: 830,650> l_pix: 6.8176e-03 \n",
      "24-12-20 17:18:38.447 - INFO: <epoch: 35, iter: 830,700> l_pix: 7.3757e-02 \n",
      "24-12-20 17:19:03.435 - INFO: <epoch: 35, iter: 830,750> l_pix: 9.0805e-03 \n",
      "24-12-20 17:19:28.664 - INFO: <epoch: 36, iter: 830,800> l_pix: 6.6574e-02 \n",
      "24-12-20 17:19:53.792 - INFO: <epoch: 36, iter: 830,850> l_pix: 4.8899e-02 \n",
      "24-12-20 17:20:18.883 - INFO: <epoch: 36, iter: 830,900> l_pix: 5.5576e-03 \n",
      "24-12-20 17:20:43.968 - INFO: <epoch: 36, iter: 830,950> l_pix: 7.5031e-03 \n",
      "24-12-20 17:21:08.871 - INFO: <epoch: 36, iter: 831,000> l_pix: 7.6211e-03 \n",
      "24-12-20 17:21:34.059 - INFO: <epoch: 37, iter: 831,050> l_pix: 4.1894e-03 \n",
      "24-12-20 17:21:59.030 - INFO: <epoch: 37, iter: 831,100> l_pix: 1.1044e-02 \n",
      "24-12-20 17:22:24.052 - INFO: <epoch: 37, iter: 831,150> l_pix: 6.0605e-03 \n",
      "24-12-20 17:22:49.059 - INFO: <epoch: 37, iter: 831,200> l_pix: 2.2856e-02 \n",
      "24-12-20 17:23:14.015 - INFO: <epoch: 37, iter: 831,250> l_pix: 6.9990e-02 \n",
      "24-12-20 17:23:39.265 - INFO: <epoch: 38, iter: 831,300> l_pix: 4.4218e-03 \n",
      "24-12-20 17:24:04.209 - INFO: <epoch: 38, iter: 831,350> l_pix: 4.3234e-03 \n",
      "24-12-20 17:24:29.256 - INFO: <epoch: 38, iter: 831,400> l_pix: 6.6408e-03 \n",
      "24-12-20 17:24:54.217 - INFO: <epoch: 38, iter: 831,450> l_pix: 1.0444e-02 \n",
      "24-12-20 17:25:19.244 - INFO: <epoch: 38, iter: 831,500> l_pix: 3.6220e-02 \n",
      "24-12-20 17:25:44.476 - INFO: <epoch: 39, iter: 831,550> l_pix: 4.1383e-03 \n",
      "24-12-20 17:26:09.558 - INFO: <epoch: 39, iter: 831,600> l_pix: 7.7955e-02 \n",
      "24-12-20 17:26:34.445 - INFO: <epoch: 39, iter: 831,650> l_pix: 3.5648e-03 \n",
      "24-12-20 17:26:58.747 - INFO: <epoch: 39, iter: 831,700> l_pix: 7.8589e-02 \n",
      "24-12-20 17:27:23.134 - INFO: <epoch: 39, iter: 831,750> l_pix: 3.5312e-02 \n",
      "24-12-20 17:27:47.856 - INFO: <epoch: 40, iter: 831,800> l_pix: 4.5212e-03 \n",
      "24-12-20 17:28:12.386 - INFO: <epoch: 40, iter: 831,850> l_pix: 1.2483e-01 \n",
      "24-12-20 17:28:36.819 - INFO: <epoch: 40, iter: 831,900> l_pix: 3.2463e-03 \n",
      "24-12-20 17:29:01.304 - INFO: <epoch: 40, iter: 831,950> l_pix: 6.2549e-02 \n",
      "24-12-20 17:29:25.790 - INFO: <epoch: 40, iter: 832,000> l_pix: 3.3779e-03 \n",
      "24-12-20 17:29:50.938 - INFO: <epoch: 41, iter: 832,050> l_pix: 6.6843e-03 \n",
      "24-12-20 17:30:15.952 - INFO: <epoch: 41, iter: 832,100> l_pix: 5.6349e-01 \n",
      "24-12-20 17:30:40.953 - INFO: <epoch: 41, iter: 832,150> l_pix: 2.7982e-01 \n",
      "24-12-20 17:31:05.941 - INFO: <epoch: 41, iter: 832,200> l_pix: 1.3849e-02 \n",
      "24-12-20 17:31:30.890 - INFO: <epoch: 41, iter: 832,250> l_pix: 3.3576e-03 \n",
      "24-12-20 17:31:56.177 - INFO: <epoch: 42, iter: 832,300> l_pix: 6.1185e-03 \n",
      "24-12-20 17:32:21.244 - INFO: <epoch: 42, iter: 832,350> l_pix: 5.7328e-02 \n",
      "24-12-20 17:32:46.251 - INFO: <epoch: 42, iter: 832,400> l_pix: 2.4120e-02 \n",
      "24-12-20 17:33:11.222 - INFO: <epoch: 42, iter: 832,450> l_pix: 7.5714e-02 \n",
      "24-12-20 17:33:36.103 - INFO: <epoch: 42, iter: 832,500> l_pix: 7.8706e-03 \n",
      "24-12-20 17:34:01.293 - INFO: <epoch: 43, iter: 832,550> l_pix: 6.5167e-03 \n",
      "24-12-20 17:34:26.190 - INFO: <epoch: 43, iter: 832,600> l_pix: 1.4025e-02 \n",
      "24-12-20 17:34:51.161 - INFO: <epoch: 43, iter: 832,650> l_pix: 4.4740e-02 \n",
      "24-12-20 17:35:16.170 - INFO: <epoch: 43, iter: 832,700> l_pix: 6.1743e-03 \n",
      "24-12-20 17:35:41.116 - INFO: <epoch: 43, iter: 832,750> l_pix: 4.4284e-02 \n",
      "24-12-20 17:36:06.218 - INFO: <epoch: 44, iter: 832,800> l_pix: 2.9175e-02 \n",
      "24-12-20 17:36:31.172 - INFO: <epoch: 44, iter: 832,850> l_pix: 1.5751e-01 \n",
      "24-12-20 17:36:56.197 - INFO: <epoch: 44, iter: 832,900> l_pix: 6.3619e-03 \n",
      "24-12-20 17:37:21.119 - INFO: <epoch: 44, iter: 832,950> l_pix: 4.7161e-03 \n",
      "24-12-20 17:37:46.073 - INFO: <epoch: 44, iter: 833,000> l_pix: 2.1889e-02 \n",
      "24-12-20 17:38:11.221 - INFO: <epoch: 45, iter: 833,050> l_pix: 1.4788e-02 \n",
      "24-12-20 17:38:36.262 - INFO: <epoch: 45, iter: 833,100> l_pix: 4.8106e-02 \n",
      "24-12-20 17:39:01.264 - INFO: <epoch: 45, iter: 833,150> l_pix: 4.2058e-02 \n",
      "24-12-20 17:39:26.317 - INFO: <epoch: 45, iter: 833,200> l_pix: 5.5520e-03 \n",
      "24-12-20 17:39:51.280 - INFO: <epoch: 45, iter: 833,250> l_pix: 4.5512e-03 \n",
      "24-12-20 17:40:16.414 - INFO: <epoch: 46, iter: 833,300> l_pix: 6.3063e-03 \n",
      "24-12-20 17:40:41.387 - INFO: <epoch: 46, iter: 833,350> l_pix: 4.0025e-01 \n",
      "24-12-20 17:41:06.431 - INFO: <epoch: 46, iter: 833,400> l_pix: 1.4967e-02 \n",
      "24-12-20 17:41:31.426 - INFO: <epoch: 46, iter: 833,450> l_pix: 5.4277e-03 \n",
      "24-12-20 17:41:56.274 - INFO: <epoch: 46, iter: 833,500> l_pix: 6.7557e-03 \n",
      "24-12-20 17:42:21.321 - INFO: <epoch: 47, iter: 833,550> l_pix: 1.6891e-02 \n",
      "24-12-20 17:42:46.257 - INFO: <epoch: 47, iter: 833,600> l_pix: 3.3689e-03 \n",
      "24-12-20 17:43:11.226 - INFO: <epoch: 47, iter: 833,650> l_pix: 5.0082e-03 \n",
      "24-12-20 17:43:36.270 - INFO: <epoch: 47, iter: 833,700> l_pix: 2.5331e-02 \n",
      "24-12-20 17:44:01.200 - INFO: <epoch: 47, iter: 833,750> l_pix: 1.1632e-02 \n",
      "24-12-20 17:44:26.291 - INFO: <epoch: 48, iter: 833,800> l_pix: 2.4420e-01 \n",
      "24-12-20 17:44:51.290 - INFO: <epoch: 48, iter: 833,850> l_pix: 3.2733e-02 \n",
      "24-12-20 17:45:16.240 - INFO: <epoch: 48, iter: 833,900> l_pix: 6.5750e-03 \n",
      "24-12-20 17:45:41.329 - INFO: <epoch: 48, iter: 833,950> l_pix: 9.4780e-02 \n",
      "24-12-20 17:46:06.264 - INFO: <epoch: 48, iter: 834,000> l_pix: 3.4704e-03 \n",
      "24-12-20 17:46:31.424 - INFO: <epoch: 49, iter: 834,050> l_pix: 5.1426e-03 \n",
      "24-12-20 17:46:56.440 - INFO: <epoch: 49, iter: 834,100> l_pix: 6.0425e-03 \n",
      "24-12-20 17:47:21.442 - INFO: <epoch: 49, iter: 834,150> l_pix: 4.4183e-01 \n",
      "24-12-20 17:47:46.285 - INFO: <epoch: 49, iter: 834,200> l_pix: 5.0996e-03 \n",
      "24-12-20 17:48:11.228 - INFO: <epoch: 49, iter: 834,250> l_pix: 4.4681e-03 \n",
      "24-12-20 17:48:36.375 - INFO: <epoch: 50, iter: 834,300> l_pix: 2.2406e-02 \n",
      "24-12-20 17:49:01.316 - INFO: <epoch: 50, iter: 834,350> l_pix: 7.5612e-02 \n",
      "24-12-20 17:49:26.333 - INFO: <epoch: 50, iter: 834,400> l_pix: 6.7736e-02 \n",
      "24-12-20 17:49:51.317 - INFO: <epoch: 50, iter: 834,450> l_pix: 8.1337e-02 \n",
      "24-12-20 17:50:16.313 - INFO: <epoch: 50, iter: 834,500> l_pix: 2.1423e-02 \n",
      "24-12-20 17:50:41.389 - INFO: <epoch: 51, iter: 834,550> l_pix: 5.1379e-03 \n",
      "24-12-20 17:51:06.434 - INFO: <epoch: 51, iter: 834,600> l_pix: 9.4305e-02 \n",
      "24-12-20 17:51:31.453 - INFO: <epoch: 51, iter: 834,650> l_pix: 4.3751e-02 \n",
      "24-12-20 17:51:56.400 - INFO: <epoch: 51, iter: 834,700> l_pix: 3.7459e-03 \n",
      "24-12-20 17:52:21.425 - INFO: <epoch: 51, iter: 834,750> l_pix: 6.2484e-03 \n",
      "24-12-20 17:52:46.530 - INFO: <epoch: 52, iter: 834,800> l_pix: 5.3541e-02 \n",
      "24-12-20 17:53:11.570 - INFO: <epoch: 52, iter: 834,850> l_pix: 6.5729e-02 \n",
      "24-12-20 17:53:36.519 - INFO: <epoch: 52, iter: 834,900> l_pix: 5.0050e-03 \n",
      "24-12-20 17:54:01.431 - INFO: <epoch: 52, iter: 834,950> l_pix: 3.5005e-03 \n",
      "24-12-20 17:54:26.423 - INFO: <epoch: 52, iter: 835,000> l_pix: 2.4545e-02 \n",
      "24-12-20 17:54:26.424 - INFO: Saving models and training states.\n",
      "24-12-20 17:54:28.907 - INFO: Saved model in [experiments/distributed_high_sr_ffhq_241220_171159/checkpoint/I835000_E52_gen.pth] ...\n",
      "24-12-20 17:54:53.993 - INFO: <epoch: 53, iter: 835,050> l_pix: 1.5941e-01 \n",
      "24-12-20 17:55:18.937 - INFO: <epoch: 53, iter: 835,100> l_pix: 4.8000e-03 \n",
      "24-12-20 17:55:43.851 - INFO: <epoch: 53, iter: 835,150> l_pix: 9.7861e-02 \n",
      "24-12-20 17:56:08.850 - INFO: <epoch: 53, iter: 835,200> l_pix: 1.5885e-02 \n",
      "24-12-20 17:56:33.818 - INFO: <epoch: 53, iter: 835,250> l_pix: 7.5899e-03 \n",
      "24-12-20 17:56:59.024 - INFO: <epoch: 54, iter: 835,300> l_pix: 2.8751e-02 \n",
      "24-12-20 17:57:23.968 - INFO: <epoch: 54, iter: 835,350> l_pix: 1.3655e-01 \n",
      "24-12-20 17:57:48.950 - INFO: <epoch: 54, iter: 835,400> l_pix: 7.0058e-03 \n",
      "24-12-20 17:58:13.911 - INFO: <epoch: 54, iter: 835,450> l_pix: 1.4755e-02 \n",
      "24-12-20 17:58:38.892 - INFO: <epoch: 54, iter: 835,500> l_pix: 1.6360e-02 \n",
      "24-12-20 17:59:04.043 - INFO: <epoch: 55, iter: 835,550> l_pix: 5.6505e-03 \n",
      "24-12-20 17:59:29.025 - INFO: <epoch: 55, iter: 835,600> l_pix: 1.1370e-01 \n",
      "24-12-20 17:59:53.939 - INFO: <epoch: 55, iter: 835,650> l_pix: 3.2213e-03 \n",
      "24-12-20 18:00:18.935 - INFO: <epoch: 55, iter: 835,700> l_pix: 5.0392e-03 \n",
      "24-12-20 18:00:43.927 - INFO: <epoch: 55, iter: 835,750> l_pix: 6.9474e-03 \n",
      "24-12-20 18:01:09.086 - INFO: <epoch: 56, iter: 835,800> l_pix: 5.4799e-03 \n",
      "24-12-20 18:01:34.135 - INFO: <epoch: 56, iter: 835,850> l_pix: 1.7849e-02 \n",
      "24-12-20 18:01:59.141 - INFO: <epoch: 56, iter: 835,900> l_pix: 6.1991e-03 \n",
      "24-12-20 18:02:24.224 - INFO: <epoch: 56, iter: 835,950> l_pix: 7.7194e-03 \n",
      "24-12-20 18:02:49.174 - INFO: <epoch: 56, iter: 836,000> l_pix: 9.7773e-02 \n",
      "24-12-20 18:03:14.240 - INFO: <epoch: 57, iter: 836,050> l_pix: 7.0169e-03 \n",
      "24-12-20 18:03:39.276 - INFO: <epoch: 57, iter: 836,100> l_pix: 8.7798e-03 \n",
      "24-12-20 18:04:04.230 - INFO: <epoch: 57, iter: 836,150> l_pix: 2.6778e-02 \n",
      "24-12-20 18:04:29.226 - INFO: <epoch: 57, iter: 836,200> l_pix: 1.8109e-02 \n",
      "24-12-20 18:04:54.216 - INFO: <epoch: 57, iter: 836,250> l_pix: 5.6034e-02 \n",
      "24-12-20 18:05:19.323 - INFO: <epoch: 58, iter: 836,300> l_pix: 3.5843e-01 \n",
      "24-12-20 18:05:44.324 - INFO: <epoch: 58, iter: 836,350> l_pix: 6.2503e-03 \n",
      "24-12-20 18:06:09.325 - INFO: <epoch: 58, iter: 836,400> l_pix: 1.6212e-02 \n",
      "24-12-20 18:06:34.377 - INFO: <epoch: 58, iter: 836,450> l_pix: 4.2297e-02 \n",
      "24-12-20 18:06:59.276 - INFO: <epoch: 58, iter: 836,500> l_pix: 7.5314e-03 \n",
      "24-12-20 18:07:24.420 - INFO: <epoch: 59, iter: 836,550> l_pix: 9.6546e-02 \n",
      "24-12-20 18:07:49.328 - INFO: <epoch: 59, iter: 836,600> l_pix: 2.1056e-02 \n",
      "24-12-20 18:08:14.468 - INFO: <epoch: 59, iter: 836,650> l_pix: 2.0567e-02 \n",
      "24-12-20 18:08:39.519 - INFO: <epoch: 59, iter: 836,700> l_pix: 8.7780e-03 \n",
      "24-12-20 18:09:04.567 - INFO: <epoch: 59, iter: 836,750> l_pix: 3.0170e-02 \n",
      "24-12-20 18:09:29.666 - INFO: <epoch: 60, iter: 836,800> l_pix: 6.0614e-02 \n",
      "24-12-20 18:09:54.630 - INFO: <epoch: 60, iter: 836,850> l_pix: 3.7456e-03 \n",
      "24-12-20 18:10:19.704 - INFO: <epoch: 60, iter: 836,900> l_pix: 2.0763e-01 \n",
      "24-12-20 18:10:44.693 - INFO: <epoch: 60, iter: 836,950> l_pix: 7.5154e-02 \n",
      "24-12-20 18:11:09.642 - INFO: <epoch: 60, iter: 837,000> l_pix: 4.2716e-02 \n",
      "24-12-20 18:11:34.826 - INFO: <epoch: 61, iter: 837,050> l_pix: 1.0862e-01 \n",
      "24-12-20 18:11:59.833 - INFO: <epoch: 61, iter: 837,100> l_pix: 2.8347e-03 \n",
      "24-12-20 18:12:24.837 - INFO: <epoch: 61, iter: 837,150> l_pix: 7.9411e-02 \n",
      "24-12-20 18:12:49.833 - INFO: <epoch: 61, iter: 837,200> l_pix: 6.5854e-03 \n",
      "24-12-20 18:13:14.796 - INFO: <epoch: 61, iter: 837,250> l_pix: 7.5946e-02 \n",
      "24-12-20 18:13:39.905 - INFO: <epoch: 62, iter: 837,300> l_pix: 2.7598e-02 \n",
      "24-12-20 18:14:04.970 - INFO: <epoch: 62, iter: 837,350> l_pix: 1.7290e-02 \n",
      "24-12-20 18:14:29.970 - INFO: <epoch: 62, iter: 837,400> l_pix: 3.8484e-02 \n",
      "24-12-20 18:14:54.966 - INFO: <epoch: 62, iter: 837,450> l_pix: 1.2910e-02 \n",
      "24-12-20 18:15:19.940 - INFO: <epoch: 62, iter: 837,500> l_pix: 7.0423e-03 \n",
      "24-12-20 18:15:45.167 - INFO: <epoch: 63, iter: 837,550> l_pix: 3.4850e-02 \n",
      "24-12-20 18:16:10.203 - INFO: <epoch: 63, iter: 837,600> l_pix: 8.4787e-03 \n",
      "24-12-20 18:16:35.243 - INFO: <epoch: 63, iter: 837,650> l_pix: 3.7642e-02 \n",
      "24-12-20 18:17:00.257 - INFO: <epoch: 63, iter: 837,700> l_pix: 1.4317e-01 \n",
      "24-12-20 18:17:25.214 - INFO: <epoch: 63, iter: 837,750> l_pix: 6.5603e-03 \n",
      "24-12-20 18:17:50.395 - INFO: <epoch: 64, iter: 837,800> l_pix: 1.6076e-02 \n",
      "24-12-20 18:18:15.486 - INFO: <epoch: 64, iter: 837,850> l_pix: 8.8629e-03 \n",
      "24-12-20 18:18:40.532 - INFO: <epoch: 64, iter: 837,900> l_pix: 4.4253e-03 \n",
      "24-12-20 18:19:05.528 - INFO: <epoch: 64, iter: 837,950> l_pix: 1.0478e-02 \n",
      "24-12-20 18:19:30.499 - INFO: <epoch: 64, iter: 838,000> l_pix: 9.9848e-02 \n",
      "24-12-20 18:19:55.705 - INFO: <epoch: 65, iter: 838,050> l_pix: 1.5638e-01 \n",
      "24-12-20 18:20:20.745 - INFO: <epoch: 65, iter: 838,100> l_pix: 1.7334e-02 \n",
      "24-12-20 18:20:45.731 - INFO: <epoch: 65, iter: 838,150> l_pix: 5.6077e-03 \n",
      "24-12-20 18:21:10.696 - INFO: <epoch: 65, iter: 838,200> l_pix: 6.1358e-03 \n",
      "24-12-20 18:21:35.726 - INFO: <epoch: 65, iter: 838,250> l_pix: 2.7732e-01 \n",
      "24-12-20 18:22:00.926 - INFO: <epoch: 66, iter: 838,300> l_pix: 2.1602e-02 \n",
      "24-12-20 18:22:25.924 - INFO: <epoch: 66, iter: 838,350> l_pix: 7.3943e-03 \n",
      "24-12-20 18:22:50.969 - INFO: <epoch: 66, iter: 838,400> l_pix: 6.1334e-02 \n",
      "24-12-20 18:23:15.816 - INFO: <epoch: 66, iter: 838,450> l_pix: 1.2069e-02 \n",
      "24-12-20 18:23:40.830 - INFO: <epoch: 66, iter: 838,500> l_pix: 4.2290e-02 \n",
      "24-12-20 18:24:06.031 - INFO: <epoch: 67, iter: 838,550> l_pix: 1.1117e-01 \n",
      "24-12-20 18:24:31.029 - INFO: <epoch: 67, iter: 838,600> l_pix: 1.0087e-02 \n",
      "24-12-20 18:24:56.008 - INFO: <epoch: 67, iter: 838,650> l_pix: 3.2988e-03 \n",
      "24-12-20 18:25:20.984 - INFO: <epoch: 67, iter: 838,700> l_pix: 5.1080e-02 \n",
      "24-12-20 18:25:45.923 - INFO: <epoch: 67, iter: 838,750> l_pix: 2.8194e-02 \n",
      "24-12-20 18:26:11.048 - INFO: <epoch: 68, iter: 838,800> l_pix: 7.1297e-02 \n",
      "24-12-20 18:26:36.041 - INFO: <epoch: 68, iter: 838,850> l_pix: 6.1927e-03 \n",
      "24-12-20 18:27:01.066 - INFO: <epoch: 68, iter: 838,900> l_pix: 4.6732e-02 \n",
      "24-12-20 18:27:26.062 - INFO: <epoch: 68, iter: 838,950> l_pix: 3.7254e-03 \n",
      "24-12-20 18:27:50.975 - INFO: <epoch: 68, iter: 839,000> l_pix: 3.8975e-03 \n",
      "24-12-20 18:28:16.170 - INFO: <epoch: 69, iter: 839,050> l_pix: 1.4672e-02 \n",
      "24-12-20 18:28:41.210 - INFO: <epoch: 69, iter: 839,100> l_pix: 7.8735e-03 \n",
      "24-12-20 18:29:06.292 - INFO: <epoch: 69, iter: 839,150> l_pix: 4.7258e-03 \n",
      "24-12-20 18:29:31.335 - INFO: <epoch: 69, iter: 839,200> l_pix: 1.2631e-02 \n",
      "24-12-20 18:29:56.376 - INFO: <epoch: 69, iter: 839,250> l_pix: 6.1633e-03 \n",
      "24-12-20 18:30:21.558 - INFO: <epoch: 70, iter: 839,300> l_pix: 1.1875e-02 \n",
      "24-12-20 18:30:46.515 - INFO: <epoch: 70, iter: 839,350> l_pix: 7.9043e-02 \n",
      "24-12-20 18:31:11.466 - INFO: <epoch: 70, iter: 839,400> l_pix: 3.4160e-03 \n",
      "24-12-20 18:31:36.367 - INFO: <epoch: 70, iter: 839,450> l_pix: 1.1547e-02 \n",
      "24-12-20 18:32:01.407 - INFO: <epoch: 70, iter: 839,500> l_pix: 3.6594e-03 \n",
      "24-12-20 18:32:26.517 - INFO: <epoch: 71, iter: 839,550> l_pix: 4.9223e-02 \n",
      "24-12-20 18:32:51.526 - INFO: <epoch: 71, iter: 839,600> l_pix: 1.0768e-01 \n",
      "24-12-20 18:33:16.431 - INFO: <epoch: 71, iter: 839,650> l_pix: 6.8540e-03 \n",
      "24-12-20 18:33:41.452 - INFO: <epoch: 71, iter: 839,700> l_pix: 4.0726e-03 \n",
      "24-12-20 18:34:06.403 - INFO: <epoch: 71, iter: 839,750> l_pix: 2.6292e-01 \n",
      "24-12-20 18:34:31.480 - INFO: <epoch: 72, iter: 839,800> l_pix: 1.5756e-02 \n",
      "24-12-20 18:34:56.486 - INFO: <epoch: 72, iter: 839,850> l_pix: 3.2227e-03 \n",
      "24-12-20 18:35:21.528 - INFO: <epoch: 72, iter: 839,900> l_pix: 1.4077e-02 \n",
      "24-12-20 18:35:46.527 - INFO: <epoch: 72, iter: 839,950> l_pix: 3.4233e-02 \n",
      "24-12-20 18:36:11.491 - INFO: <epoch: 72, iter: 840,000> l_pix: 5.4738e-03 \n",
      "sampling loop time step: 100%|██████████████| 2000/2000 [03:11<00:00, 10.44it/s]\n",
      "sampling loop time step: 100%|██████████████| 2000/2000 [03:02<00:00, 10.96it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/sr.py\", line 112, in <module>\n",
      "    for _,  val_data in enumerate(val_loader):\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/_utils.py\", line 715, in reraise\n",
      "    raise exception\n",
      "IndexError: Caught IndexError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/rv1057/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/data/LRHR_dataset.py\", line 89, in __getitem__\n",
      "    img_SR = Image.open(self.sr_path[index]).convert(\"RGB\")\n",
      "                        ~~~~~~~~~~~~^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/sr.py -p train -c /scratch/rv1057/Image-Super-Resolution-via-Iterative-Refinement/config/sr_sr3_64_512.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp2CAl3prreO"
   },
   "source": [
    "Copy the resulting checkpoint (which is just weights of a model) to your drive for later use. Check the last job on experiments folder, copy its name here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8fbkhhSp6qm"
   },
   "outputs": [],
   "source": [
    "%cp -r /content/Image-Super-Resolution-via-Iterative-Refinement/experiments/distributed_high_sr_ffhq_241207_015530/checkpoint /content/drive/MyDrive/checkpoints_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkHoD9kssHvn"
   },
   "source": [
    "Run for inference to check the results (same name as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHPu2dq0rDlP",
    "outputId": "bc487af5-aeb3-490f-af4e-1aae1a3437e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/content/infer.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python infer.py -c /content/Image-Super-Resolution-via-Iterative-Refinement/config/sr_sr3_64_512.json"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
